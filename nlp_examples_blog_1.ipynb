{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DoNWiuVAP-y5",
        "outputId": "f30a6b1d-cff8-43af-8913-3ba8916bf83b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Collecting spacytextblob\n",
            "  Downloading spacytextblob-5.0.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: textblob>=0.18.0.post0 in /usr/local/lib/python3.11/dist-packages (from spacytextblob) (0.19.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.7.14)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.11/dist-packages (from textblob>=0.18.0.post0->spacytextblob) (3.9.1)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob>=0.18.0.post0->spacytextblob) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob>=0.18.0.post0->spacytextblob) (2024.11.6)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading spacytextblob-5.0.0-py3-none-any.whl (4.2 kB)\n",
            "Installing collected packages: spacytextblob\n",
            "Successfully installed spacytextblob-5.0.0\n"
          ]
        }
      ],
      "source": [
        "%pip install spacy spacytextblob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "\n",
        "#\n",
        "# First we need to get the existing model\n",
        "#\n",
        "nlp_example = spacy.load(\"en_core_web_sm\")\n"
      ],
      "metadata": {
        "id": "owCG7XummB7R"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Come up with a sentence which would help us show examples for most of the topics.\n",
        "#\n",
        "text_input = \"\"\"\n",
        "I am Shreyas Jain and am from Karnataka. I was born in the year 1991, currently I'm working as Principle SDET.\n",
        "This is just a temporary piece of paragraph. Ideally, this will be a huge data.\n",
        "Since these sentences serves as examples, again and again I am adding more words to this paragraph to identify and use this as an example to help us understand the concept.\n",
        "NOTE: THIS IS AN INTENTIONAL ATTEMPT TO MAKE THINGS MORE DIFFICULT.\n",
        "100 Words or more.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "Is-hSDN7tj33"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Tokenization: Convert a sentence to tokens\n",
        "#\n",
        "nlp_tokens = nlp_example(text_input)\n",
        "tokens = [token.text for token in nlp_tokens]\n",
        "print(\"Total number of tokens available : \", len(tokens))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFRRcvPvw5Ye",
        "outputId": "775c50d5-c554-47d3-bdd9-206603895441"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of tokens available :  100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Stop words removal and lowercasing\n",
        "#\n",
        "stop_words_removed_n_lower_case = [token.text.lower() for token in nlp_tokens if not token.is_stop]\n",
        "print(\"Total number of tokens after removing stop words and making it lowercase:\", len(stop_words_removed_n_lower_case))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MbPYZfc2vck",
        "outputId": "52138d48-3008-4e18-b6f9-8bf6bb3b81f5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of tokens after removing stop words and making it lowercase: 52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicate tokens by converting the list to a set and then back to a list\n",
        "unique_tokens = list(set(stop_words_removed_n_lower_case))\n",
        "print(\"Total number of unique tokens:\", len(unique_tokens))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwEVbkxd2yyV",
        "outputId": "b16390eb-c284-41ca-f2fa-671a01c294e5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of unique tokens: 37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# We can remove the special characters if needed.\n",
        "#\n",
        "cleaned_unique_tokens = [re.sub(r'[^a-zA-Z0-9]', '', token) for token in unique_tokens]\n",
        "cleaned_unique_tokens = [token for token in cleaned_unique_tokens if token]\n",
        "print(\"Unique tokens after removing special characters:\", len(cleaned_unique_tokens))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3r4wKbGq21Jp",
        "outputId": "ee9d8802-28a7-4b04-b0f0-45afea184b6d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens after removing special characters: 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Parts of speech tagging\n",
        "#\n",
        "for each_token in cleaned_unique_tokens[:5]:\n",
        "  print(f\"Token {each_token}, belongs to POS: {nlp_example(each_token)[0].pos_}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwhtWDUU24IV",
        "outputId": "f5f26c71-fd5f-413a-d145-7254ffbe95ed"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token concept, belongs to POS: NOUN\n",
            "Token karnataka, belongs to POS: PROPN\n",
            "Token help, belongs to POS: VERB\n",
            "Token temporary, belongs to POS: ADJ\n",
            "Token sdet, belongs to POS: NOUN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Check the Named Entitiy Recogniation for the given tokens\n",
        "#\n",
        "for each_token in nlp_tokens.ents:\n",
        "  print(f\"Token {each_token}, recognized as : {each_token.label_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA1uMMU625kH",
        "outputId": "96be0006-4096-49ec-be50-3af4b4716052"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token Shreyas Jain, recognized as : PERSON\n",
            "Token Karnataka, recognized as : GPE\n",
            "Token the year 1991, recognized as : DATE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Sentiment Analysis for the following statements\n",
        "#\n",
        "from spacytextblob.spacytextblob import SpacyTextBlob\n",
        "nlp_example.add_pipe('spacytextblob')"
      ],
      "metadata": {
        "id": "wng3BXQa26f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analysis_result(value):\n",
        "  if value > 0:\n",
        "    return \"Positive\"\n",
        "  elif value < 0:\n",
        "    return \"Negative\"\n",
        "  else:\n",
        "    return \"Neutral\""
      ],
      "metadata": {
        "id": "RG3_88R_4Hf0"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = \"These topics are very difficult to understand\"\n",
        "sentiment_result = nlp_example(text_input)._.blob.sentiment_assessments.assessments[0][1]\n",
        "print(f\"Sentiment score for '{text_input}': {sentiment_result} i.e., {analysis_result(sentiment_result)}\")\n",
        "\n",
        "\n",
        "text_input = \"These topics are very easy to understand\"\n",
        "sentiment_result = nlp_example(text_input)._.blob.sentiment_assessments.assessments[0][1]\n",
        "print(f\"Sentiment score for '{text_input}': {sentiment_result} i.e., {analysis_result(sentiment_result)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR2OH9Or6rPq",
        "outputId": "6c1bffac-6f6d-4a41-e295-807ae0ecc267"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment score for 'These topics are very difficult to understand': -0.65 i.e., Negative\n",
            "Sentiment score for 'These topics are very easy to understand': 0.5633333333333334 i.e., Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g9lElgTv6sVX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}